{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCjLt29pJYmB"
   },
   "source": [
    "<center>\n",
    "\n",
    "#<b>CS353 ML Lab 3</b>\n",
    "\n",
    "## Name: K V Sumanth Reddy\n",
    "## Roll No: 181CO225\n",
    "---\n",
    "\n",
    "###Q: Write a program in python to implement the na√Øve Bayesian classifier and Bayesian classifier for a sample training data set. Compute the accuracy of the classifier.\n",
    "---\n",
    "####Dataset Used: Breast Cancer Dataset\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcG3JjWkuazq"
   },
   "source": [
    "##Importing Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "orc44VVfJYmV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "Gz2wJ-pcJYmZ",
    "outputId": "6ee2ca20-1554-4d7c-8c51-72ba8ac28dc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>17.460</td>\n",
       "      <td>39.28</td>\n",
       "      <td>113.40</td>\n",
       "      <td>920.6</td>\n",
       "      <td>0.09812</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05966</td>\n",
       "      <td>0.5366</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>3.002</td>\n",
       "      <td>49.00</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.02785</td>\n",
       "      <td>0.02602</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>0.01226</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>22.51</td>\n",
       "      <td>44.87</td>\n",
       "      <td>141.20</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>0.13650</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.32410</td>\n",
       "      <td>0.20660</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.08496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.740</td>\n",
       "      <td>17.91</td>\n",
       "      <td>88.12</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.07944</td>\n",
       "      <td>0.06376</td>\n",
       "      <td>0.02881</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>0.05580</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7574</td>\n",
       "      <td>1.573</td>\n",
       "      <td>21.47</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.01592</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>15.34</td>\n",
       "      <td>22.46</td>\n",
       "      <td>97.19</td>\n",
       "      <td>725.9</td>\n",
       "      <td>0.09711</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.15640</td>\n",
       "      <td>0.06019</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>12.960</td>\n",
       "      <td>18.29</td>\n",
       "      <td>84.18</td>\n",
       "      <td>525.2</td>\n",
       "      <td>0.07351</td>\n",
       "      <td>0.07899</td>\n",
       "      <td>0.04057</td>\n",
       "      <td>0.01883</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.05899</td>\n",
       "      <td>0.2357</td>\n",
       "      <td>1.2990</td>\n",
       "      <td>2.397</td>\n",
       "      <td>20.21</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.03713</td>\n",
       "      <td>0.03452</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>0.02632</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>14.13</td>\n",
       "      <td>24.61</td>\n",
       "      <td>96.31</td>\n",
       "      <td>621.9</td>\n",
       "      <td>0.09329</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.16040</td>\n",
       "      <td>0.06608</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.07247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>12.760</td>\n",
       "      <td>13.37</td>\n",
       "      <td>82.29</td>\n",
       "      <td>504.1</td>\n",
       "      <td>0.08794</td>\n",
       "      <td>0.07948</td>\n",
       "      <td>0.04052</td>\n",
       "      <td>0.02548</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.06140</td>\n",
       "      <td>0.3265</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>2.346</td>\n",
       "      <td>25.18</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.02768</td>\n",
       "      <td>0.03137</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.01731</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>14.19</td>\n",
       "      <td>16.40</td>\n",
       "      <td>92.04</td>\n",
       "      <td>618.8</td>\n",
       "      <td>0.11940</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.17690</td>\n",
       "      <td>0.08411</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.08253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.06601</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>2.8780</td>\n",
       "      <td>2.759</td>\n",
       "      <td>25.17</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>0.01674</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.03044</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>10.85</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.15260</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>11.940</td>\n",
       "      <td>20.76</td>\n",
       "      <td>77.87</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.08605</td>\n",
       "      <td>0.10110</td>\n",
       "      <td>0.06574</td>\n",
       "      <td>0.03791</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.06766</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>1.3900</td>\n",
       "      <td>3.198</td>\n",
       "      <td>21.91</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.05156</td>\n",
       "      <td>0.04387</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>0.01872</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>13.24</td>\n",
       "      <td>27.29</td>\n",
       "      <td>92.20</td>\n",
       "      <td>546.1</td>\n",
       "      <td>0.11160</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>0.23650</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.09981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>11.740</td>\n",
       "      <td>14.69</td>\n",
       "      <td>76.31</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.08099</td>\n",
       "      <td>0.09661</td>\n",
       "      <td>0.06726</td>\n",
       "      <td>0.02639</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.06758</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>1.345</td>\n",
       "      <td>13.04</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.03916</td>\n",
       "      <td>0.04017</td>\n",
       "      <td>0.015280</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>12.45</td>\n",
       "      <td>17.60</td>\n",
       "      <td>81.25</td>\n",
       "      <td>473.8</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.2793</td>\n",
       "      <td>0.26900</td>\n",
       "      <td>0.10560</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>11.690</td>\n",
       "      <td>24.44</td>\n",
       "      <td>76.37</td>\n",
       "      <td>406.4</td>\n",
       "      <td>0.12360</td>\n",
       "      <td>0.15520</td>\n",
       "      <td>0.04515</td>\n",
       "      <td>0.04531</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.07405</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>1.9780</td>\n",
       "      <td>2.158</td>\n",
       "      <td>20.95</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.03495</td>\n",
       "      <td>0.01865</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>0.01560</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>12.98</td>\n",
       "      <td>32.19</td>\n",
       "      <td>86.12</td>\n",
       "      <td>487.7</td>\n",
       "      <td>0.17680</td>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.13950</td>\n",
       "      <td>0.13080</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0.09970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>11.460</td>\n",
       "      <td>18.16</td>\n",
       "      <td>73.59</td>\n",
       "      <td>403.1</td>\n",
       "      <td>0.08853</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>0.03344</td>\n",
       "      <td>0.01502</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.06243</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>1.0590</td>\n",
       "      <td>2.475</td>\n",
       "      <td>22.93</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.02221</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.01894</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>12.68</td>\n",
       "      <td>21.61</td>\n",
       "      <td>82.69</td>\n",
       "      <td>489.8</td>\n",
       "      <td>0.11440</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.05509</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.07638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>11.500</td>\n",
       "      <td>18.45</td>\n",
       "      <td>73.28</td>\n",
       "      <td>407.4</td>\n",
       "      <td>0.09345</td>\n",
       "      <td>0.05991</td>\n",
       "      <td>0.02638</td>\n",
       "      <td>0.02069</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.05934</td>\n",
       "      <td>0.3927</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>2.684</td>\n",
       "      <td>26.99</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.01065</td>\n",
       "      <td>0.01245</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.02292</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>12.97</td>\n",
       "      <td>22.46</td>\n",
       "      <td>83.12</td>\n",
       "      <td>508.9</td>\n",
       "      <td>0.11830</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>0.08105</td>\n",
       "      <td>0.06544</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.06487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius mean texture  ... worst fractal dimension Target\n",
       "239      17.460        39.28  ...                 0.08496      0\n",
       "149      13.740        17.91  ...                 0.07014      1\n",
       "402      12.960        18.29  ...                 0.07247      1\n",
       "312      12.760        13.37  ...                 0.08253      1\n",
       "416       9.405        21.70  ...                 0.08304      1\n",
       "286      11.940        20.76  ...                 0.09981      1\n",
       "510      11.740        14.69  ...                 0.09879      1\n",
       "537      11.690        24.44  ...                 0.09970      1\n",
       "304      11.460        18.16  ...                 0.07638      1\n",
       "251      11.500        18.45  ...                 0.06487      1\n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "data = pd.DataFrame(cancer.data, columns=[cancer.feature_names])\n",
    "data['Target'] = pd.Series(data=cancer.target, index=data.index)\n",
    "data.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp6Oli1auud-"
   },
   "source": [
    "##Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RFvMcvedJYmg"
   },
   "outputs": [],
   "source": [
    "x,y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZmvjFM3zJYmj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "661Y9i5fvTGR"
   },
   "source": [
    "##Training the Naive Bayes model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qedrKlY4JYmm",
    "outputId": "80b8abed-be3e-4c06-819c-99a286795274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.71%\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "acc1=model.score(x_test,y_test)*100\n",
    "print(\"Accuracy: {:.2f}%\".format(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xmZkQEu5JYmn"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJveP1pOJYmo",
    "outputId": "60b63197-d1be-466d-e9c8-3e5b31c46668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91        53\n",
      "           1       0.95      0.96      0.95        90\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.93      0.93      0.93       143\n",
      "weighted avg       0.94      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whcB4uTiy2Fc",
    "outputId": "36057d73-e273-419b-8efb-9b84d9dc57df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[48  5]\n",
      " [ 4 86]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqm7jPLNyCrw"
   },
   "source": [
    "#USING FEATURE SCALING\n",
    "###This is performed to normalize few columns (due to their higher values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qF2v46YKJYmt"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WoTylSK1ZyY",
    "outputId": "c8281a88-37ab-43bf-bae2-004a21748254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.61%\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "acc2=model.score(x_test,y_test)*100\n",
    "print(\"Accuracy: {:.2f}%\".format(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T8fRVirXzwqK"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fl2VB9-kzwqM",
    "outputId": "8106f510-3eac-45d5-ea99-305e36a8bd03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        53\n",
      "           1       0.93      0.93      0.93        90\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.91      0.91      0.91       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99Uf09enzwqO",
    "outputId": "549f2761-f5a5-4eab-abe1-5e6a710717aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[47  6]\n",
      " [ 6 84]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5C86zBG15qF"
   },
   "source": [
    "#Accuracy Comparison with and without feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1w6tjjci14rX",
    "outputId": "5dfd4358-dc6b-49f9-8d0c-9a75e0a33b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy without Feature Scaling:  93.7062937062937 \n",
      " Accuracy with Feature Scaling:  91.6083916083916\n"
     ]
    }
   ],
   "source": [
    "print(\" Accuracy without Feature Scaling: \",acc1,\"\\n\",\"Accuracy with Feature Scaling: \",acc2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive Bayesian (Breast Cancer Dataset)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
